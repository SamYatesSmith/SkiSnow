{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "In this notebook, we will perform data cleaning and preparation for all resorts across the Alps. This includes loading the raw data, handling missing values, correcting data types, and saving the cleaned data for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths and Helper Functions\n",
    "\n",
    "To efficiently load and clean data for all resorts, we'll define the root directories and create helper functions to process each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(a).  Handling Special Characters in File Names\n",
    "Issues can arrise from special characters.  We need to normalise file names before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise file names to remove accents\n",
    "def normalize_name(file_name):\n",
    "    return unicodedata.normalize('NFKD', file_name).encode('ascii', 'ignore').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directories for raw and processed data\n",
    "raw_data_root = 'data/raw/cds'\n",
    "processed_data_root = 'data/processed/cds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/SkiSnow/notebooks\n",
      "Checking directory: ../data/raw/cds\n",
      "Directory ../data/raw/cds exists!\n",
      "Checking country path: ../data/raw/cds/austrian_alps\n",
      "Checking resort path: ../data/raw/cds/austrian_alps/kitzbühel\n",
      "Found file: kitzbühel.csv\n",
      "Checking resort path: ../data/raw/cds/austrian_alps/st._anton\n",
      "Found file: st._anton.csv\n",
      "Checking resort path: ../data/raw/cds/austrian_alps/sölden\n",
      "Found file: sölden.csv\n",
      "Checking country path: ../data/raw/cds/french_alps\n",
      "Checking resort path: ../data/raw/cds/french_alps/chamonix\n",
      "Found file: chamonix.csv\n",
      "Checking resort path: ../data/raw/cds/french_alps/les_trois_vallées\n",
      "Found file: les_trois_vallées.csv\n",
      "Checking resort path: ../data/raw/cds/french_alps/val_d'isère_&_tignes\n",
      "Found file: val_d'isère_&_tignes.csv\n",
      "Checking country path: ../data/raw/cds/italian_alps\n",
      "Checking resort path: ../data/raw/cds/italian_alps/cortina_d'ampezzo\n",
      "Found file: cortina_d'ampezzo.csv\n",
      "Checking resort path: ../data/raw/cds/italian_alps/sestriere\n",
      "Found file: sestriere.csv\n",
      "Checking resort path: ../data/raw/cds/italian_alps/val_gardena\n",
      "Found file: val_gardena.csv\n",
      "Checking country path: ../data/raw/cds/slovenian_alps\n",
      "Checking resort path: ../data/raw/cds/slovenian_alps/kranjska_gora\n",
      "Found file: kranjska_gora.csv\n",
      "Checking resort path: ../data/raw/cds/slovenian_alps/krvavec\n",
      "Found file: krvavec.csv\n",
      "Checking resort path: ../data/raw/cds/slovenian_alps/mariborsko_pohorje\n",
      "Found file: mariborsko_pohorje.csv\n",
      "Checking country path: ../data/raw/cds/swiss_alps\n",
      "Checking resort path: ../data/raw/cds/swiss_alps/st._moritz\n",
      "Found file: st._moritz.csv\n",
      "Checking resort path: ../data/raw/cds/swiss_alps/verbier\n",
      "Found file: verbier.csv\n",
      "Checking resort path: ../data/raw/cds/swiss_alps/zermatt\n",
      "Found file: zermatt.csv\n",
      "Found 15 CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Function to get list of all CSV files in the raw data directory\n",
    "def get_all_csv_files(root_dir):\n",
    "    # Print the root directory path to verify\n",
    "    print(f\"Checking directory: {root_dir}\")\n",
    "    \n",
    "    if not os.path.exists(root_dir):\n",
    "        print(f\"Directory {root_dir} does not exist.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Directory {root_dir} exists!\")\n",
    "    \n",
    "    csv_files = []\n",
    "    for country in os.listdir(root_dir):\n",
    "        normalized_country = normalize_name(country)\n",
    "        country_path = os.path.join(root_dir, country)\n",
    "        print(f\"Checking country path: {country_path}\")\n",
    "        \n",
    "        if os.path.isdir(country_path):\n",
    "            for resort in os.listdir(country_path):\n",
    "                normalized_resort = normalize_name(resort)\n",
    "                resort_path = os.path.join(country_path, resort)\n",
    "                print(f\"Checking resort path: {resort_path}\")\n",
    "                \n",
    "                if os.path.isdir(resort_path):\n",
    "                    for file in os.listdir(resort_path):\n",
    "                        normalized_file = normalize_name(file)\n",
    "                        print(f\"Found file: {file}\")\n",
    "                        \n",
    "                        if normalized_file.endswith('.csv'):\n",
    "                            file_path = os.path.join(resort_path, file)\n",
    "                            csv_files.append({\n",
    "                                'country': normalized_country,\n",
    "                                'resort': normalized_resort,\n",
    "                                'file_path': file_path\n",
    "                            })\n",
    "    return csv_files\n",
    "\n",
    "# Set the correct root directory\n",
    "raw_data_root = '../data/raw/cds'\n",
    "\n",
    "# Print current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Get list of all CSV files\n",
    "csv_files = get_all_csv_files(raw_data_root)\n",
    "print(f\"Found {len(csv_files)} CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle missing values \n",
    "\n",
    "As the data is not available (from this source) until 2021-03-23, we must remove all missing rows until this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory where all CSV files are stored\n",
    "raw_data_root = '../data/raw/cds'\n",
    "\n",
    "# Function to clean and filter a single CSV file\n",
    "def clean_and_filter_data(file_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert the date column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Filter rows to only keep data from 2021-03-23 onward\n",
    "    df = df[df['date'] >= '2021-03-23']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3(a) Function to iterate over all CSV files.  We then clean, and filter them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data/raw/cds/austrian_alps/kitzbühel/kitzbühel.csv...\n",
      "Processing ../data/raw/cds/austrian_alps/st._anton/st._anton.csv...\n",
      "Processing ../data/raw/cds/austrian_alps/sölden/sölden.csv...\n",
      "Processing ../data/raw/cds/french_alps/chamonix/chamonix.csv...\n",
      "Processing ../data/raw/cds/french_alps/les_trois_vallées/les_trois_vallées.csv...\n",
      "Processing ../data/raw/cds/french_alps/val_d'isère_&_tignes/val_d'isère_&_tignes.csv...\n",
      "Processing ../data/raw/cds/italian_alps/cortina_d'ampezzo/cortina_d'ampezzo.csv...\n",
      "Processing ../data/raw/cds/italian_alps/sestriere/sestriere.csv...\n",
      "Processing ../data/raw/cds/italian_alps/val_gardena/val_gardena.csv...\n",
      "Processing ../data/raw/cds/slovenian_alps/kranjska_gora/kranjska_gora.csv...\n",
      "Processing ../data/raw/cds/slovenian_alps/krvavec/krvavec.csv...\n",
      "Processing ../data/raw/cds/slovenian_alps/mariborsko_pohorje/mariborsko_pohorje.csv...\n",
      "Processing ../data/raw/cds/swiss_alps/st._moritz/st._moritz.csv...\n",
      "Processing ../data/raw/cds/swiss_alps/verbier/verbier.csv...\n",
      "Processing ../data/raw/cds/swiss_alps/zermatt/zermatt.csv...\n",
      "                         date  temperature_2m_max  temperature_2m_min  \\\n",
      "570 2021-03-23 22:00:00+00:00              7.3395             -3.9605   \n",
      "571 2021-03-24 22:00:00+00:00              6.7395             -2.2605   \n",
      "572 2021-03-25 22:00:00+00:00              7.9395             -2.1605   \n",
      "573 2021-03-26 22:00:00+00:00              4.7895             -2.2605   \n",
      "574 2021-03-27 22:00:00+00:00              8.2395             -3.8105   \n",
      "\n",
      "     rain_sum  snowfall_sum  \n",
      "570  0.000000      0.000000  \n",
      "571  0.000000      0.000000  \n",
      "572  0.003386      0.003858  \n",
      "573  0.062126      5.060945  \n",
      "574  0.000000      0.000000  \n"
     ]
    }
   ],
   "source": [
    "def process_all_csv_files(root_dir):\n",
    "    all_dataframes = {}  # Dictionary to store cleaned dataframes for each resort\n",
    "    \n",
    "    for country in os.listdir(root_dir):\n",
    "        country_path = os.path.join(root_dir, country)\n",
    "        if os.path.isdir(country_path):\n",
    "            for resort in os.listdir(country_path):\n",
    "                resort_path = os.path.join(country_path, resort)\n",
    "                if os.path.isdir(resort_path):\n",
    "                    for file in os.listdir(resort_path):\n",
    "                        if file.endswith('.csv'):\n",
    "                            file_path = os.path.join(resort_path, file)\n",
    "                            print(f\"Processing {file_path}...\")\n",
    "                            \n",
    "                            # Clean and filter the data\n",
    "                            cleaned_df = clean_and_filter_data(file_path)\n",
    "                            \n",
    "                            # Store the cleaned dataframe using a key (country_resort) in a dictionary\n",
    "                            resort_name = f\"{country}_{resort}\"\n",
    "                            all_dataframes[resort_name] = cleaned_df\n",
    "    \n",
    "    return all_dataframes\n",
    "\n",
    "# Process all CSV files and store the results in a dictionary\n",
    "cleaned_dataframes = process_all_csv_files(raw_data_root)\n",
    "\n",
    "# Example: Accessing cleaned data for a specific resort (e.g., 'french_alps_chamonix')\n",
    "df_chamonix_cleaned = cleaned_dataframes['french_alps_chamonix']\n",
    "print(df_chamonix_cleaned.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
