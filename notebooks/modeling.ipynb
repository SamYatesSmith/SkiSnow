{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling for Snow Depth Prediction\n",
    "\n",
    "This notebook is focused on preparing the data for modeling, addressing multicollinearity, and creating training, validation, and testing sets. We will proceed with the following steps:\n",
    "- Loading the Processed Data\n",
    "- Creating Lag Features and Derived Variables\n",
    "- Handling Multicollinearity\n",
    "- Splitting the Data into Training, Validation, and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Libraries and Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modeling modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_training import train_random_forest, evaluate_model\n",
    "from src.models.model_evaluation import plot_actual_vs_predicted, plot_feature_importances\n",
    "from src.models.utils import save_model, save_split_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined data with shape (57862, 12)\n"
     ]
    }
   ],
   "source": [
    "# Adjust the path based on your current working directory\n",
    "data_path = os.path.join('..', 'data', 'processed', 'processed_data_for_modeling.csv')\n",
    "\n",
    "# Load the combined processed data\n",
    "model_data = pd.read_csv(data_path)\n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "model_data['date'] = pd.to_datetime(model_data['date'])\n",
    "\n",
    "# Display the shape to confirm loading\n",
    "logging.info(f\"Loaded combined data with shape {model_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after encoding: ['date', 'temperature_min', 'temperature_max', 'precipitation_sum', 'snow_depth', 'season_id', 'is_operating_season', 'snow_depth_lag1', 'snow_depth_lag7', 'temperature_avg', 'temperature_avg_squared', 'resort_cortina_d_ampezzo', 'resort_kitzbuhel', 'resort_kranjska_gora', 'resort_krvavec', 'resort_les_trois_vallees', 'resort_mariborsko_pohorje', 'resort_sestriere', 'resort_solden', 'resort_st_anton', 'resort_st_moritz', 'resort_val_d_isere_tignes', 'resort_val_gardena', 'resort_verbier']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encode the 'resort' feature\n",
    "model_data = pd.get_dummies(model_data, columns=['resort'], drop_first=True)\n",
    "\n",
    "# Display the columns to confirm encoding\n",
    "logging.info(f\"Columns after encoding: {model_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preparing Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after filtering for operating season: (39668, 24)\n",
      "Initial shape of X (including 'snow_depth'): (39668, 23)\n",
      "Initial shape of y: (39668,)\n"
     ]
    }
   ],
   "source": [
    "# Filter data for operating season\n",
    "data_operating = model_data[model_data['is_operating_season'] == True].reset_index(drop=True)\n",
    "logging.info(f\"Data shape after filtering for operating season: {data_operating.shape}\")\n",
    "\n",
    "# Define the target variable\n",
    "y = data_operating['snow_depth']\n",
    "\n",
    "# Exclude 'date' and 'snow_depth' from features\n",
    "feature_columns = [col for col in data_operating.columns if col != 'date']\n",
    "\n",
    "# Create the features DataFrame\n",
    "X = data_operating[feature_columns].copy()\n",
    "\n",
    "logging.info(f\"Initial shape of X (including 'snow_depth'): {X.shape}\")\n",
    "logging.info(f\"Initial shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check for Non-Numeric Columns & Handle \"season_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns before processing: ['season_id', 'is_operating_season', 'resort_cortina_d_ampezzo', 'resort_kitzbuhel', 'resort_kranjska_gora', 'resort_krvavec', 'resort_les_trois_vallees', 'resort_mariborsko_pohorje', 'resort_sestriere', 'resort_solden', 'resort_st_anton', 'resort_st_moritz', 'resort_val_d_isere_tignes', 'resort_val_gardena', 'resort_verbier']\n",
      "One-Hot Encoded 'season_id' and updated X.\n",
      "Converted boolean columns to integers: ['is_operating_season', 'resort_cortina_d_ampezzo', 'resort_kitzbuhel', 'resort_kranjska_gora', 'resort_krvavec', 'resort_les_trois_vallees', 'resort_mariborsko_pohorje', 'resort_sestriere', 'resort_solden', 'resort_st_anton', 'resort_st_moritz', 'resort_val_d_isere_tignes', 'resort_val_gardena', 'resort_verbier', 'season_1991-1992', 'season_1992-1993', 'season_1993-1994', 'season_1994-1995', 'season_1995-1996', 'season_1996-1997', 'season_1997-1998', 'season_1998-1999', 'season_1999-2000', 'season_2000-2001', 'season_2001-2002', 'season_2002-2003', 'season_2003-2004', 'season_2004-2005', 'season_2005-2006', 'season_2006-2007', 'season_2007-2008', 'season_2008-2009', 'season_2009-2010', 'season_2010-2011', 'season_2011-2012', 'season_2012-2013', 'season_2013-2014', 'season_2014-2015', 'season_2015-2016', 'season_2016-2017', 'season_2017-2018', 'season_2018-2019', 'season_2019-2020', 'season_2020-2021', 'season_2021-2022', 'season_2022-2023', 'season_2023-2024']\n",
      "Non-numeric columns after processing: []\n",
      "Data types after processing:\n",
      "temperature_min              float64\n",
      "temperature_max              float64\n",
      "precipitation_sum            float64\n",
      "snow_depth                   float64\n",
      "is_operating_season            int64\n",
      "snow_depth_lag1              float64\n",
      "snow_depth_lag7              float64\n",
      "temperature_avg              float64\n",
      "temperature_avg_squared      float64\n",
      "resort_cortina_d_ampezzo       int64\n",
      "resort_kitzbuhel               int64\n",
      "resort_kranjska_gora           int64\n",
      "resort_krvavec                 int64\n",
      "resort_les_trois_vallees       int64\n",
      "resort_mariborsko_pohorje      int64\n",
      "resort_sestriere               int64\n",
      "resort_solden                  int64\n",
      "resort_st_anton                int64\n",
      "resort_st_moritz               int64\n",
      "resort_val_d_isere_tignes      int64\n",
      "resort_val_gardena             int64\n",
      "resort_verbier                 int64\n",
      "season_1991-1992               int64\n",
      "season_1992-1993               int64\n",
      "season_1993-1994               int64\n",
      "season_1994-1995               int64\n",
      "season_1995-1996               int64\n",
      "season_1996-1997               int64\n",
      "season_1997-1998               int64\n",
      "season_1998-1999               int64\n",
      "season_1999-2000               int64\n",
      "season_2000-2001               int64\n",
      "season_2001-2002               int64\n",
      "season_2002-2003               int64\n",
      "season_2003-2004               int64\n",
      "season_2004-2005               int64\n",
      "season_2005-2006               int64\n",
      "season_2006-2007               int64\n",
      "season_2007-2008               int64\n",
      "season_2008-2009               int64\n",
      "season_2009-2010               int64\n",
      "season_2010-2011               int64\n",
      "season_2011-2012               int64\n",
      "season_2012-2013               int64\n",
      "season_2013-2014               int64\n",
      "season_2014-2015               int64\n",
      "season_2015-2016               int64\n",
      "season_2016-2017               int64\n",
      "season_2017-2018               int64\n",
      "season_2018-2019               int64\n",
      "season_2019-2020               int64\n",
      "season_2020-2021               int64\n",
      "season_2021-2022               int64\n",
      "season_2022-2023               int64\n",
      "season_2023-2024               int64\n",
      "dtype: object\n",
      "All features are now numeric and ready for Polynomial Features.\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns\n",
    "non_numeric_cols = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "logging.info(f\"Non-numeric columns before processing: {non_numeric_cols}\")\n",
    "\n",
    "# Handle 'season_id' column\n",
    "# One-Hot Encode 'season_id' if it's in the features\n",
    "if 'season_id' in X.columns:\n",
    "    # One-Hot Encode 'season_id'\n",
    "    season_dummies = pd.get_dummies(X['season_id'], prefix='season', drop_first=True)\n",
    "    # Drop 'season_id' and add the encoded variables\n",
    "    X = pd.concat([X.drop(columns=['season_id']), season_dummies], axis=1)\n",
    "    logging.info(\"One-Hot Encoded 'season_id' and updated X.\")\n",
    "else:\n",
    "    logging.warning(\"'season_id' column not found in features.\")\n",
    "\n",
    "# Convert boolean columns to integers\n",
    "bool_columns = X.select_dtypes(include=['bool']).columns.tolist()\n",
    "if bool_columns:\n",
    "    X[bool_columns] = X[bool_columns].astype(int)\n",
    "    logging.info(f\"Converted boolean columns to integers: {bool_columns}\")\n",
    "\n",
    "# Verify all columns are now numeric\n",
    "non_numeric_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "logging.info(f\"Non-numeric columns after processing: {non_numeric_cols}\")\n",
    "logging.info(\"Data types after processing:\")\n",
    "logging.info(X.dtypes)\n",
    "\n",
    "if not non_numeric_cols:\n",
    "    logging.info(\"All features are now numeric and ready for Polynomial Features.\")\n",
    "else:\n",
    "    logging.error(\"There are still non-numeric features that need to be encoded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lag Features\n",
    "\n",
    "Incorporate lagged values of snow depth and other relevant features to capture temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created lag feature 'snow_depth_lag1'.\n",
      "Created lag feature 'snow_depth_lag7'.\n",
      "Created lag feature 'snow_depth_lag14'.\n",
      "Created lag feature 'snow_depth_lag21'.\n",
      "Created lag feature 'temperature_avg_lag1'.\n",
      "Created lag feature 'temperature_avg_lag7'.\n",
      "Created lag feature 'temperature_avg_lag14'.\n",
      "Created lag feature 'temperature_avg_lag21'.\n",
      "Created lag feature 'precipitation_sum_lag1'.\n",
      "Created lag feature 'precipitation_sum_lag7'.\n",
      "Created lag feature 'precipitation_sum_lag14'.\n",
      "Created lag feature 'precipitation_sum_lag21'.\n",
      "Shape of X after adding lag features: (39647, 65)\n",
      "Shape of y after adding lag features: (39647,)\n"
     ]
    }
   ],
   "source": [
    "# Define lag periods\n",
    "lags = [1, 7, 14, 21]  # You can adjust these based on domain knowledge\n",
    "\n",
    "# Features to create lag features for\n",
    "lag_features = ['snow_depth', 'temperature_avg', 'precipitation_sum']\n",
    "\n",
    "for feature in lag_features:\n",
    "    for lag in lags:\n",
    "        lag_col = f\"{feature}_lag{lag}\"\n",
    "        if feature in X.columns:\n",
    "            X[lag_col] = X[feature].shift(lag)\n",
    "            logging.info(f\"Created lag feature '{lag_col}'.\")\n",
    "        else:\n",
    "            logging.warning(f\"Feature '{feature}' not found in X. Skipping lag creation for this feature.\")\n",
    "\n",
    "# Drop rows with NaN values resulting from lagging\n",
    "# Ensure that any rows dropped are reflected in both X and y\n",
    "initial_length = len(X)\n",
    "X = X.dropna().reset_index(drop=True)\n",
    "y = y.iloc[X.index].reset_index(drop=True)\n",
    "\n",
    "logging.info(f\"Shape of X after adding lag features: {X.shape}\")\n",
    "logging.info(f\"Shape of y after adding lag features: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Handling Multicollinearity\n",
    "\n",
    "Before splitting the data, it's important to check for multicollinearity among features.\n",
    "\n",
    "Calculating the Variance Inflation Factor (VIF) for each feature is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/SkiSnow/venv/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Variance Inflation Factors:\n",
      "                    feature        VIF\n",
      "0           temperature_min        inf\n",
      "1           temperature_max        inf\n",
      "6           temperature_avg        inf\n",
      "3       is_operating_season  73.420689\n",
      "56     temperature_avg_lag1   5.537389\n",
      "..                      ...        ...\n",
      "53         season_2023-2024   1.268330\n",
      "7   temperature_avg_squared   1.239701\n",
      "61   precipitation_sum_lag7   1.218813\n",
      "62  precipitation_sum_lag14   1.210810\n",
      "63  precipitation_sum_lag21   1.187878\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "Features with VIF > 10: ['temperature_min', 'temperature_max', 'is_operating_season', 'temperature_avg']\n",
      "Dropped feature 'temperature_min' due to high VIF.\n",
      "                    feature        VIF\n",
      "2       is_operating_season  73.420689\n",
      "5           temperature_avg  21.341858\n",
      "0           temperature_max  17.439587\n",
      "55     temperature_avg_lag1   5.537389\n",
      "19           resort_verbier   4.779857\n",
      "..                      ...        ...\n",
      "52         season_2023-2024   1.268330\n",
      "6   temperature_avg_squared   1.239701\n",
      "60   precipitation_sum_lag7   1.218813\n",
      "61  precipitation_sum_lag14   1.210810\n",
      "62  precipitation_sum_lag21   1.187878\n",
      "\n",
      "[63 rows x 2 columns]\n",
      "Dropped feature 'temperature_max' due to high VIF.\n",
      "                    feature        VIF\n",
      "1       is_operating_season  71.564148\n",
      "54     temperature_avg_lag1   5.488337\n",
      "4           temperature_avg   5.085692\n",
      "18           resort_verbier   4.671043\n",
      "7          resort_kitzbuhel   4.029748\n",
      "..                      ...        ...\n",
      "51         season_2023-2024   1.267652\n",
      "59   precipitation_sum_lag7   1.218369\n",
      "60  precipitation_sum_lag14   1.210659\n",
      "61  precipitation_sum_lag21   1.187620\n",
      "5   temperature_avg_squared   1.116318\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "Dropped feature 'is_operating_season' due to high VIF.\n",
      "                     feature       VIF\n",
      "2            snow_depth_lag7  5.838331\n",
      "51          snow_depth_lag14  5.664006\n",
      "53      temperature_avg_lag1  5.557901\n",
      "3            temperature_avg  5.148351\n",
      "1            snow_depth_lag1  5.124061\n",
      "..                       ...       ...\n",
      "59   precipitation_sum_lag14  1.366952\n",
      "16        resort_val_gardena  1.360176\n",
      "5   resort_cortina_d_ampezzo  1.351981\n",
      "60   precipitation_sum_lag21  1.341907\n",
      "50          season_2023-2024  1.130080\n",
      "\n",
      "[61 rows x 2 columns]\n",
      "Dropped feature 'temperature_avg' due to high VIF.\n",
      "                      feature       VIF\n",
      "2             snow_depth_lag7  5.837981\n",
      "50           snow_depth_lag14  5.663952\n",
      "1             snow_depth_lag1  5.123502\n",
      "51           snow_depth_lag21  4.772798\n",
      "16             resort_verbier  3.367964\n",
      "5            resort_kitzbuhel  3.076499\n",
      "12            resort_st_anton  2.723073\n",
      "6        resort_kranjska_gora  2.610777\n",
      "53       temperature_avg_lag7  2.420261\n",
      "54      temperature_avg_lag14  2.337657\n",
      "11              resort_solden  2.295380\n",
      "9   resort_mariborsko_pohorje  2.238007\n",
      "52       temperature_avg_lag1  2.205244\n",
      "55      temperature_avg_lag21  2.096369\n",
      "7              resort_krvavec  1.989943\n",
      "10           resort_sestriere  1.953089\n",
      "13           resort_st_moritz  1.787388\n",
      "35           season_2009-2010  1.781295\n",
      "14  resort_val_d_isere_tignes  1.765796\n",
      "34           season_2008-2009  1.765211\n",
      "37           season_2011-2012  1.762964\n",
      "38           season_2012-2013  1.706229\n",
      "39           season_2013-2014  1.689406\n",
      "17           season_1991-1992  1.657856\n",
      "43           season_2017-2018  1.651355\n",
      "36           season_2010-2011  1.647043\n",
      "3     temperature_avg_squared  1.646957\n",
      "40           season_2014-2015  1.618697\n",
      "33           season_2007-2008  1.606277\n",
      "8    resort_les_trois_vallees  1.594712\n",
      "44           season_2018-2019  1.594474\n",
      "48           season_2022-2023  1.560127\n",
      "25           season_1999-2000  1.555168\n",
      "28           season_2002-2003  1.551095\n",
      "24           season_1998-1999  1.542536\n",
      "56     precipitation_sum_lag1  1.539155\n",
      "46           season_2020-2021  1.535710\n",
      "41           season_2015-2016  1.533743\n",
      "47           season_2021-2022  1.532141\n",
      "21           season_1995-1996  1.518930\n",
      "29           season_2003-2004  1.509122\n",
      "45           season_2019-2020  1.508856\n",
      "0           precipitation_sum  1.505187\n",
      "32           season_2006-2007  1.492948\n",
      "42           season_2016-2017  1.490560\n",
      "19           season_1993-1994  1.487914\n",
      "26           season_2000-2001  1.480314\n",
      "20           season_1994-1995  1.478722\n",
      "27           season_2001-2002  1.469401\n",
      "31           season_2005-2006  1.459218\n",
      "18           season_1992-1993  1.452041\n",
      "22           season_1996-1997  1.447989\n",
      "30           season_2004-2005  1.431494\n",
      "23           season_1997-1998  1.416573\n",
      "57     precipitation_sum_lag7  1.374361\n",
      "58    precipitation_sum_lag14  1.366885\n",
      "15         resort_val_gardena  1.359838\n",
      "4    resort_cortina_d_ampezzo  1.351728\n",
      "59    precipitation_sum_lag21  1.341886\n",
      "49           season_2023-2024  1.129965\n",
      "Final Variance Inflation Factors:\n",
      "                      feature       VIF\n",
      "2             snow_depth_lag7  5.837981\n",
      "50           snow_depth_lag14  5.663952\n",
      "1             snow_depth_lag1  5.123502\n",
      "51           snow_depth_lag21  4.772798\n",
      "16             resort_verbier  3.367964\n",
      "5            resort_kitzbuhel  3.076499\n",
      "12            resort_st_anton  2.723073\n",
      "6        resort_kranjska_gora  2.610777\n",
      "53       temperature_avg_lag7  2.420261\n",
      "54      temperature_avg_lag14  2.337657\n",
      "11              resort_solden  2.295380\n",
      "9   resort_mariborsko_pohorje  2.238007\n",
      "52       temperature_avg_lag1  2.205244\n",
      "55      temperature_avg_lag21  2.096369\n",
      "7              resort_krvavec  1.989943\n",
      "10           resort_sestriere  1.953089\n",
      "13           resort_st_moritz  1.787388\n",
      "35           season_2009-2010  1.781295\n",
      "14  resort_val_d_isere_tignes  1.765796\n",
      "34           season_2008-2009  1.765211\n",
      "37           season_2011-2012  1.762964\n",
      "38           season_2012-2013  1.706229\n",
      "39           season_2013-2014  1.689406\n",
      "17           season_1991-1992  1.657856\n",
      "43           season_2017-2018  1.651355\n",
      "36           season_2010-2011  1.647043\n",
      "3     temperature_avg_squared  1.646957\n",
      "40           season_2014-2015  1.618697\n",
      "33           season_2007-2008  1.606277\n",
      "8    resort_les_trois_vallees  1.594712\n",
      "44           season_2018-2019  1.594474\n",
      "48           season_2022-2023  1.560127\n",
      "25           season_1999-2000  1.555168\n",
      "28           season_2002-2003  1.551095\n",
      "24           season_1998-1999  1.542536\n",
      "56     precipitation_sum_lag1  1.539155\n",
      "46           season_2020-2021  1.535710\n",
      "41           season_2015-2016  1.533743\n",
      "47           season_2021-2022  1.532141\n",
      "21           season_1995-1996  1.518930\n",
      "29           season_2003-2004  1.509122\n",
      "45           season_2019-2020  1.508856\n",
      "0           precipitation_sum  1.505187\n",
      "32           season_2006-2007  1.492948\n",
      "42           season_2016-2017  1.490560\n",
      "19           season_1993-1994  1.487914\n",
      "26           season_2000-2001  1.480314\n",
      "20           season_1994-1995  1.478722\n",
      "27           season_2001-2002  1.469401\n",
      "31           season_2005-2006  1.459218\n",
      "18           season_1992-1993  1.452041\n",
      "22           season_1996-1997  1.447989\n",
      "30           season_2004-2005  1.431494\n",
      "23           season_1997-1998  1.416573\n",
      "57     precipitation_sum_lag7  1.374361\n",
      "58    precipitation_sum_lag14  1.366885\n",
      "15         resort_val_gardena  1.359838\n",
      "4    resort_cortina_d_ampezzo  1.351728\n",
      "59    precipitation_sum_lag21  1.341886\n",
      "49           season_2023-2024  1.129965\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    \n",
    "def calculate_vif(X):\n",
    "    \"\"\"\n",
    "    Calculate Variance Inflation Factor (VIF) for each feature in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing features and their VIF values.\n",
    "    \"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif['feature'] = X.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif\n",
    "\n",
    "# Exclude 'snow_depth' from VIF calculation if present\n",
    "features_to_exclude = ['snow_depth']\n",
    "X_vif = X.drop(columns=features_to_exclude, errors='ignore').copy()\n",
    "\n",
    "# Calculate initial VIF\n",
    "vif_data = calculate_vif(X_vif)\n",
    "logging.info(\"Initial Variance Inflation Factors:\")\n",
    "logging.info(vif_data.sort_values('VIF', ascending=False))\n",
    "\n",
    "# Identify features with VIF > 10\n",
    "high_vif = vif_data[vif_data['VIF'] > 10]['feature'].tolist()\n",
    "logging.info(f\"Features with VIF > 10: {high_vif}\")\n",
    "\n",
    "# Iteratively remove features with high VIF\n",
    "for feature in high_vif:\n",
    "    if feature in X.columns:\n",
    "        X = X.drop(columns=[feature])\n",
    "        logging.info(f\"Dropped feature '{feature}' due to high VIF.\")\n",
    "        # Recalculate VIF after dropping the feature\n",
    "        X_vif = X.drop(columns=features_to_exclude, errors='ignore').copy()\n",
    "        vif_data = calculate_vif(X_vif)\n",
    "        logging.info(vif_data.sort_values('VIF', ascending=False))\n",
    "    else:\n",
    "        logging.warning(f\"Feature '{feature}' already removed.\")\n",
    "\n",
    "# Final VIF after removal\n",
    "final_vif = calculate_vif(X_vif)\n",
    "logging.info(\"Final Variance Inflation Factors:\")\n",
    "logging.info(final_vif.sort_values('VIF', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Adding Polynomial Features\n",
    "\n",
    "Now that all non-numeric columns have been handled, we can safely apply Polynomial Features to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot apply PolynomialFeatures to missing features: ['temperature_avg']\n",
      "Proceeding with available features only.\n",
      "Shape of X after adding polynomial features to selected features: (39647, 62)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Define features to apply PolynomialFeatures\n",
    "selected_features = ['temperature_avg', 'precipitation_sum']\n",
    "\n",
    "# Check which selected features are present in X\n",
    "available_features = [feature for feature in selected_features if feature in X.columns]\n",
    "missing_features = [feature for feature in selected_features if feature not in X.columns]\n",
    "\n",
    "if missing_features:\n",
    "    logging.warning(f\"Cannot apply PolynomialFeatures to missing features: {missing_features}\")\n",
    "    logging.info(\"Proceeding with available features only.\")\n",
    "else:\n",
    "    logging.info(\"All selected features are available for PolynomialFeatures.\")\n",
    "\n",
    "if available_features:\n",
    "    # Initialize PolynomialFeatures with degree 2\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    \n",
    "    # Fit and transform only the available features\n",
    "    X_poly_selected = poly.fit_transform(X[available_features])\n",
    "    \n",
    "    # Get the new feature names for selected features\n",
    "    poly_features_selected = poly.get_feature_names_out(available_features)\n",
    "    \n",
    "    # Create a DataFrame for polynomial features\n",
    "    X_poly_df = pd.DataFrame(X_poly_selected, columns=poly_features_selected)\n",
    "    \n",
    "    # Drop the original selected features from X\n",
    "    X = X.drop(columns=available_features)\n",
    "    \n",
    "    # Concatenate the polynomial features back to X\n",
    "    X = pd.concat([X.reset_index(drop=True), X_poly_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    logging.info(f\"Shape of X after adding polynomial features to selected features: {X.shape}\")\n",
    "else:\n",
    "    logging.warning(\"No features available for PolynomialFeatures. Skipping this step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Splitting the Data\n",
    "\n",
    "Since the data is time-series data, it's important to split it in a way that respects the temporal order and thus avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 (a) Split the data into training, validation, and test sets using time-based splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (27752, 62), y_train size: (27752,)\n",
      "Validation set size: (5947, 62), y_val size: (5947,)\n",
      "Test set size: (5948, 62), y_test size: (5948,)\n",
      "All splits are aligned correctly.\n"
     ]
    }
   ],
   "source": [
    "# Define the sizes for training, validation, and testing sets\n",
    "total_length = len(X)\n",
    "train_size = int(0.7 * len(X))\n",
    "val_size = int(0.15 * len(X))\n",
    "test_size = total_length - train_size - val_size\n",
    "\n",
    "# Split the data\n",
    "X_train = X.iloc[:train_size].reset_index(drop=True)\n",
    "y_train = y.iloc[:train_size].reset_index(drop=True)\n",
    "\n",
    "X_val = X.iloc[train_size:train_size + val_size].reset_index(drop=True)\n",
    "y_val = y.iloc[train_size:train_size + val_size].reset_index(drop=True)\n",
    "\n",
    "X_test = X.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "y_test = y.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "\n",
    "logging.info(f\"Training set size: {X_train.shape}, y_train size: {y_train.shape}\")\n",
    "logging.info(f\"Validation set size: {X_val.shape}, y_val size: {y_val.shape}\")\n",
    "logging.info(f\"Test set size: {X_test.shape}, y_test size: {y_test.shape}\")\n",
    "\n",
    "# Verify alignment\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Mismatch in training set.\"\n",
    "assert X_val.shape[0] == y_val.shape[0], \"Mismatch in validation set.\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Mismatch in test set.\"\n",
    "\n",
    "logging.info(\"All splits are aligned correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Proceeding with Modeling\n",
    "\n",
    "The data is now prepared.  We can proceed to build and evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 (a) Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "\n",
      "Optimised Random Forest Regressor Evaluation on Validation Set:\n",
      "Mean Squared Error: 1173.11\n",
      "R-squared: 0.94\n",
      "\n",
      "Length of y_test: 5948\n",
      "Length of y_test_pred: 5948\n",
      "\n",
      "Optimised Random Forest Regressor Evaluation on Test Set:\n",
      "Mean Squared Error: 1452.32\n",
      "R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Train the Random Forest Regressor\n",
    "best_rf_model, best_params = train_random_forest(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    param_dist=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Predict and evaluate on Validation Set\n",
    "val_metrics = evaluate_model(best_rf_model, X_val, y_val, dataset_name=\"Validation\")\n",
    "\n",
    "# Predict on Test Set\n",
    "test_metrics = evaluate_model(best_rf_model, X_test, y_test, dataset_name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Plotting Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Actual vs Predicted for Validation Set\n",
    "plot_actual_vs_predicted(\n",
    "    y_true=y_val,\n",
    "    y_pred=best_rf_model.predict(X_val),\n",
    "    dataset_name=\"Validation\",\n",
    "    save_dir=os.path.join('..', 'src', 'models', 'plots')\n",
    ")\n",
    "\n",
    "# Plot Actual vs Predicted for Test Set\n",
    "plot_actual_vs_predicted(\n",
    "    y_true=y_test,\n",
    "    y_pred=best_rf_model.predict(X_test),\n",
    "    dataset_name=\"Test\",\n",
    "    save_dir=os.path.join('..', 'src', 'models', 'plots')\n",
    ")\n",
    "\n",
    "# Plot Feature Importances\n",
    "plot_feature_importances(\n",
    "    model=best_rf_model,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    save_dir=os.path.join('..', 'src', 'models', 'plots')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved to ../src/models/best_rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to save the model\n",
    "model_save_dir = os.path.join('..', 'src', 'models', 'saved_models')\n",
    "\n",
    "# Define the path to save the model\n",
    "model_save_path = os.path.join(model_save_dir, 'best_rf_model.pkl')\n",
    "\n",
    "# Save the trained model\n",
    "save_model(best_rf_model, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Saving the Split Datasets\n",
    "\n",
    "After training and evaluating the model, we'll save the split datasets (`X_train.csv`, `y_train.csv`, `X_val.csv`, `y_val.csv`, `X_test.csv`, `y_test.csv`) to the `data/processed/modeling_data/` directory. This ensures that these datasets can be easily accessed for future evaluations, residual analysis, and other analyses without the need to regenerate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved split datasets to ../data/processed/modeling_data\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to save the split datasets\n",
    "modeling_data_dir = os.path.join('..', 'data', 'processed', 'modeling_data')\n",
    "\n",
    "# Save the split datasets\n",
    "save_split_datasets(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    save_dir=modeling_data_dir\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
